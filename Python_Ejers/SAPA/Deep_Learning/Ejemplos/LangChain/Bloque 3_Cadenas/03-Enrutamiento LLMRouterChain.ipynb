{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "#  Enrutamiento con LLM Router Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2128d1c-62d1-4681-abe1-754a1410e632",
   "metadata": {},
   "source": [
    "## Importar librerías iniciales e instancia de modelo de chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d81e4f-8739-4a19-abf9-7515304fc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import SequentialChain, LLMChain #importamos el SequentialChain que es el modelo completo\n",
    "f = open('/home/iabd/clave_gpt.txt')\n",
    "api_key = f.read().strip()\n",
    "llm = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c70034-3204-41f7-af62-f25c9cc5a2de",
   "metadata": {},
   "source": [
    "### Plantillas de enrutamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddea86e7-9240-4369-a938-38aaff2c6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template (prompt) para soporte básico a clientes de coches\n",
    "plantilla_soporte_basico_cliente = '''Eres una persona que asiste a los clientes de automóviles con preguntas básicas que pueden\n",
    "necesitar en su día a día y que explica los conceptos de una manera que sea simple de entender. Asume que no tienen conocimiento\n",
    "previo. Esta es la pregunta del usuario/n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb91294c-14cc-48f8-9fd3-12f59f178fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template (prompt) para soporte avanzados a nuestros expertos en mecánica\n",
    "plantilla_soporte_avanzado_mecánico = '''Eres un experto en mecánica que explicas consultas avanzadas a los mecánicos\n",
    "de la plantilla. Puedes asumir que cualquier que está preguntando tiene conocimientos avanzados de mecánica. \n",
    "Esta es la pregunta del usuario/n{input}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92180e62-1a77-4f85-bad4-44225a08d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se pueden añadir todas las plantillas que necesitemos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2c29f-dd15-4821-ac3a-2f5f6321b172",
   "metadata": {},
   "source": [
    "### Prompts a enrutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad19090-69a5-481d-87cf-2d4c8119c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debemos crear una lista de diccionarios, cada diccionario contiene su nombre, la descripción (en base a la cual el enrutador\n",
    "#hará su trabajo) y el prompt a usar en cada caso\n",
    "prompt_infos = [\n",
    "    {'name':'mecánica básica','description': 'Responde preguntas básicas de mecánicas a clientes',\n",
    "     'prompt_template':plantilla_soporte_basico_cliente},\n",
    "    {'name':'mecánica avanzada','description': 'Responde preguntas avanzadas de mecánica a expertos con conocimiento previo',\n",
    "     'prompt_template':plantilla_soporte_avanzado_mecánico},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c659b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LO QUE VIENE A CONTINUACIÓN ES AGNÓSTICO DEL CASO DE USO Y LO PUEDES UTILIZAR PARA TODOS LOS CASOS DE USO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7e03a-a8ed-4405-ae33-7770deccd0a9",
   "metadata": {},
   "source": [
    "### ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b759163-2c87-45c7-8b0d-47cb1f6df76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa78da93-c52d-4ea3-b680-7ae5c677b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5691/3171874237.py:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "#Creamos un diccionario de objetos LLMChain con las posibles cadenas destino\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed26ebca-bd7c-41c4-8c20-d0e90e06490a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mecánica básica': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='Eres una persona que asiste a los clientes de automóviles con preguntas básicas que pueden\\nnecesitar en su día a día y que explica los conceptos de una manera que sea simple de entender. Asume que no tienen conocimiento\\nprevio. Esta es la pregunta del usuario/n{input}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x781ab3956f90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x781ab39ec9b0>, root_client=<openai.OpenAI object at 0x781abc3462d0>, root_async_client=<openai.AsyncOpenAI object at 0x781ab3956fc0>, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'mecánica avanzada': LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='Eres un experto en mecánica que explicas consultas avanzadas a los mecánicos\\nde la plantilla. Puedes asumir que cualquier que está preguntando tiene conocimientos avanzados de mecánica. \\nEsta es la pregunta del usuario/n{input}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x781ab3956f90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x781ab39ec9b0>, root_client=<openai.OpenAI object at 0x781abc3462d0>, root_async_client=<openai.AsyncOpenAI object at 0x781ab3956fc0>, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfabfe49-a9dc-4d0e-9e40-bfc042719487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el prompt y cadena por defecto puesto que son argumento obligatorios que usaremos posteriormente\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15856b11-d9ab-4a7a-b7af-6f4726ab0d2d",
   "metadata": {},
   "source": [
    "### Multi Routing Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd303e5-44b1-424d-93e6-7340d24cfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos una plantilla que podremos formatear su parámetro {destinations} que tendrá cada nombre y descripción de la información de prompts\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548eae05-4292-48a0-8147-1b4d1fb0433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE) #El parámetro importante es {destinations}, debemos formatearlo en tipo string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152ed30-7c5e-46ec-bd9f-8fa2ff42950e",
   "metadata": {},
   "source": [
    "### Destinos de Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635cbf1e-52ce-4d26-a25f-ddc81fa21340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una string global con todos los destinos de routing usando el nombre y descripción de \"prompt_infos\"\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac5f3a0-32e7-45a5-8564-b433d42eeeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mecánica básica: Responde preguntas básicas de mecánicas a clientes\\nmecánica avanzada: Responde preguntas avanzadas de mecánica a expertos con conocimiento previo'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c0879-3d03-4b2b-b98b-1476a809ed25",
   "metadata": {},
   "source": [
    "### Router Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbfd595-c65a-49e6-91f6-026528f58e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefd428a-059e-41ba-b49e-b0016b72541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str #Formateamos la plantilla con nuestros destinos en la string destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(), #Para transformar el objeto JSON parseándolo a una string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf19d2c3-0bbb-4a0d-8d69-ac177e814afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "mecánica básica: Responde preguntas básicas de mecánicas a clientes\n",
      "mecánica avanzada: Responde preguntas avanzadas de mecánica a expertos con conocimiento previo\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template) #verificamos que se ha formateado correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ba041-a4fe-425d-a6e7-0d357dae6ef6",
   "metadata": {},
   "source": [
    "### Routing Chain Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a82b26-438a-4882-bcdd-aa7548f4f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4100748e-75a5-4e40-998d-a3a959d9a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5600e9-f60f-466c-8321-ec2f32e0cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5691/2474013140.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, #El objeto con los posibles LLMChain que creamos al inicio\n",
    "                         default_chain=default_chain, verbose=True #Indicamos el LLMChain por defecto (obligatorio)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a77635b-b475-4bdf-bb35-d0ca5983911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "mecánica básica: {'input': '¿Cómo cambio el aceite de mi coche?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '¿Cómo cambio el aceite de mi coche?',\n",
       " 'text': 'Cambiar el aceite de tu coche es una tarea importante para mantener el motor en buenas condiciones. Aquí te dejo algunos pasos sencillos para que puedas hacerlo tú mismo:\\n\\n1. Reúne todos los materiales necesarios: aceite de motor nuevo, filtro de aceite nuevo, recipiente para recoger el aceite usado, llave de filtro de aceite, llave de drenaje de aceite, embudo y trapos.\\n\\n2. Estaciona tu coche en una superficie plana y deja enfriar el motor por unos minutos.\\n\\n3. Localiza el tapón de drenaje de aceite en el fondo del motor y coloca el recipiente debajo. Afloja el tapón con la llave de drenaje y deja que el aceite usado drene completamente.\\n\\n4. Retira el filtro de aceite antiguo con la llave correspondiente y coloca el nuevo filtro en su lugar, asegurándote de lubricar el anillo de sellado con un poco de aceite limpio.\\n\\n5. Vuelve a colocar el tapón de drenaje de aceite y apriétalo correctamente. Llena el motor con la cantidad de aceite recomendada para tu vehículo a través del orificio de llenado, utilizando el embudo.\\n\\n6. Enciende el motor y verifica que no haya fugas de aceite. Apaga el motor, espera unos minutos y verifica nuevamente el nivel de aceite con la varilla de medición.\\n\\n¡Listo! Has cambiado con éxito el aceite de tu coche. Recuerda desechar adecuadamente el aceite usado y el filtro en un lugar designado para el reciclaje. ¡Y no dudes en volver si necesitas más ayuda con tu automóvil!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"¿Cómo cambio el aceite de mi coche?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c7ed272-808e-4974-ad21-6af0ba31fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "mecánica avanzada: {'input': '¿Cómo funcionan internamente los catalizadores?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '¿Cómo funcionan internamente los catalizadores?',\n",
       " 'text': 'Los catalizadores son dispositivos muy importantes en el sistema de escape de un vehículo, ya que tienen la función de reducir las emisiones contaminantes producidas en la combustión del motor. \\n\\nInternamente, un catalizador está formado por un sustrato cerámico recubierto con metales preciosos como platino, paladio y rodio, que actúan como catalizadores en las reacciones químicas que tienen lugar dentro de él. \\n\\nCuando los gases de escape pasan a través del catalizador, los hidrocarburos no quemados, el monóxido de carbono y los óxidos de nitrógeno se encuentran con los metales preciosos en la superficie del sustrato cerámico. Estos metales actúan como catalizadores y facilitan la reacción química que convierte estos gases nocivos en gases menos dañinos como dióxido de carbono, agua y nitrógeno. \\n\\nEl diseño del sustrato cerámico del catalizador permite una mayor superficie de contacto entre los gases de escape y los metales preciosos, lo que maximiza la eficiencia de la conversión de los gases contaminantes. \\n\\nEn resumen, los catalizadores funcionan internamente gracias a la presencia de metales preciosos que actúan como catalizadores en las reacciones químicas que tienen lugar dentro de ellos, convirtiendo los gases nocivos en gases menos dañinos para el medio ambiente.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"¿Cómo funciona internamente un catalizador?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60400b3d-aab3-4dee-8b1e-f7096fa78aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_gpu312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
