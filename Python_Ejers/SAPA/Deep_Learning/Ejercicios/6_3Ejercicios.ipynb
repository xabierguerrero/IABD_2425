{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from transformers import pipeline, BertTokenizer, TFBertForSequenceClassification, DetrImageProcessor, DetrForObjectDetection\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡GPU encontrada!\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739475227.838754   22216 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739475227.839882   22216 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739475227.839997   22216 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"¡GPU encontrada!\")\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "else:\n",
    "    print(\"¡GPU no encontrada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crecimiento de memoria configurado para las GPUs.\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Crecimiento de memoria configurado para las GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error al configurar crecimiento de memoria: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1\n",
    "Utiliza un modelo preentrenado de Hugging Face que clasifique textos en neutral y subjetivo y clasifica las siguientes opiniones:\n",
    "\n",
    "* \"I think the new city park is a great addition to the neighborhood. It offers a lot of green space and is a great place for families to spend time outdoors.\"\n",
    "\n",
    "* \"The customer service at the restaurant was disappointing. We had to wait over an hour just to get our drinks, and the staff seemed uninterested in helping us.\"\n",
    "\n",
    "* \"This book is just okay. It's not the best I've read, but it's not the worst either. The plot is somewhat predictable, but the characters are somewhat interesting.\"\n",
    "\n",
    "* \"The local library has extended its operating hours on weekends. It is now open from 9 a.m. to 7 p.m. on Saturdays and Sundays\"\n",
    "\n",
    "El resultado lo tiene que mostrar  de la siguiente forma:\n",
    "\n",
    "* Texto: XXX \n",
    "* Clasificación: Y con una confianza del X%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"alexandrainst/da-subjectivivity-classification-base\"\n",
    "classifier_subje = pipeline(\"text-classification\", model=model_name, device=-1) #CPU\n",
    "classifier_subje = pipeline(\"text-classification\", model=model_name) #GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'objective', 'score': 0.999790608882904}]\n",
      "[{'label': 'objective', 'score': 0.9819163680076599}]\n",
      "[{'label': 'subjective', 'score': 0.999299168586731}]\n",
      "[{'label': 'objective', 'score': 0.9990546107292175}]\n"
     ]
    }
   ],
   "source": [
    "frases=[\n",
    "    \"I think the new city park is a great addition to the neighborhood. It offers a lot of green space and is a great place for families to spend time outdoors.\",\n",
    "    \"The customer service at the restaurant was disappointing. We had to wait over an hour just to get our drinks, and the staff seemed uninterested in helping us.\",\n",
    "    \"This book is just okay. It's not the best I've read, but it's not the worst either. The plot is somewhat predictable, but the characters are somewhat interesting.\",\n",
    "    \"The local library has extended its operating hours on weekends. It is now open from 9 a.m. to 7 p.m. on Saturdays and Sundays\"\n",
    "]\n",
    "\n",
    "for frase in frases:\n",
    "    predict=classifier_subje(frase)\n",
    "    print(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2\n",
    "Traduce el siguiente texto del inglés al español usando un modelo preentrenado de Hugging Face: \"The achievements of artificial intelligence are impressive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"SoyGema/english-spanish\"\n",
    "modelo_traductor = pipeline(\"translation_en_to_es\", model=model_name, device=-1) #CPU\n",
    "modelo_traductor = pipeline(\"translation_en_to_es\", model=model_name) #GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Die Errungenungen der artificial intelligence sind impresionant.'}]\n"
     ]
    }
   ],
   "source": [
    "frase=\"The achievements of artificial intelligence are impressive.\"\n",
    "traducc=modelo_traductor(frase)\n",
    "print(traducc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3\n",
    "Genera un texto continuando la siguiente frase: \"Los logros de la inteligencia artificial...\"\n",
    "\n",
    "Usa gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 4\n",
    "Entrena un modelo de análisis de sentimientos en un pequeño conjunto de datos personalizado usando un modelo de Hugging Face. Supongamos que tienes el siguiente conjunto de datos (evidentemente con este conjunto de datos tan pequeño no vamos a ningún lado, se trata de simular el proceso):\n",
    "\n",
    "* \"I enjoy playing football.\", Positivo\n",
    "* \"The restaurant had poor service.\", Negativo\n",
    "* \"Such a beautiful day outside!\", Positivo\n",
    "\n",
    "Si quieres puedes usar el modelo bert-base-uncased\n",
    "\n",
    "Los pasos generales que puedes seguir son:\n",
    "* Prepara los datos de entrenamiento (X e y).\n",
    "* Carga un modelo preentrenado de Transformers y su tokenizador.\n",
    "* Preprocesa los datos para que sean compatibles con el modelo.\n",
    "* Compila el modelo con una función de pérdida y un optimizador.\n",
    "* Entrena el modelo con los datos.\n",
    "* Evalúa el modelo con algunos datos (\"I enjoy playing basketboall.\", Positivo y \"I hate rainning days.\", Negativo).\n",
    "* Predice nuevos datos (\"The restaurant had a good service.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 5\n",
    "Utiliza un modelo preentrenado de Hugging Face para generar una descripción (caption) para una imagen dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 6\n",
    "Elige un modelo de detcción de objetos de Hugging Face y aplícalo a una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 7\n",
    "Genera un texto usando un modelo de generción de texto (gpt2).\n",
    "Usa el texto creado como entrada para un modelo de generación de imágenes (stable-diffusion).\n",
    "\n",
    "El texto de entrada para el primer modelo va a ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 8 (OPCIONAL)\n",
    "Encadena con sentido tres modelos de Hugging Face para realizar una tarea de NLP, una de visión y una de generación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Salvador3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
