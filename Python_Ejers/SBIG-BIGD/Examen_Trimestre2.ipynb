{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 19:30:25 WARN Utils: Your hostname, iadb-10 resolves to a loopback address: 127.0.1.1; using 172.20.104.46 instead (on interface wlp44s0f0)\n",
      "25/03/10 19:30:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/10 19:30:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, trim, concat_ws, to_date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "import time\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\").appName(\"pyspark_dataframe\").getOrCreate()\n",
    ")\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el archivo Turismo.csv lleva a cabo las siguientes acciones utilizando Dataframes de SPARK.\n",
    "\n",
    "En este ejercicio debes crear el archivo: Ejercicio1.ipynb  con los pasos llevados a cabo y subirlo a moodle.\n",
    "En el archivo que entregues que se vean todos los resultados de las operaciones.\n",
    "\n",
    "\n",
    "    1. Cargar los datos en un DataFrame de Spark infiriendo el esquema. HECHO\n",
    "    2. Mostrar el esquema del DataFrame y los primeros 5 registros. HECHO\n",
    "    3. Convertir la columna \"FECHA\" en formato de fecha (dd/MM/yyyy) y mostrar el esquema. HECHO\n",
    "    4. Listar las 3 visitas con la mayor puntuación de: SATISFACCION_GLOBAL. HECHO\n",
    "    5. Contar cuántas visitas se realizaron en cada mes del año y mostrarlas en orden descendente. HECHO\n",
    "    6. Filtrar las visitas realizadas en septiembre y mostrar sólo los campos: VISITA y SATISFACCION_GLOBAL. HECHO\n",
    "    7. Reemplazar valores nulos en la columna: LO_PEOR con el valor: \"Sin comentarios\". HECHO\n",
    "    8. Crear una nueva columna llamada SATISFACCION_PROMEDIO que sea el promedio de las 3 categorías de satisfacción: SATISFACCION_INFOR, SATISFACCION_RECORRIDO, SATISFACCION_GUIA. Debes crear tu propia función de usuario y registrarla como una función de Spark. Con SQL y sin SQL.\n",
    "    9. Guardar el resultado final en formato .csv de tal forma que si el archivo ya existe que lo sobreescriba.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID;VISITA;MES;FECHA;SATISFACCION_INFOR;SATISFACCION_RECORRIDO;SATISFACCION_GUIA;SATISFACCION_GLOBAL;LO_MEJOR;LO_PEOR;OPINION;SUGERENCIAS\n",
      "12;LEYENDAS, CASAS ENCANTADAS Y LUCES EN  NAVIDAD CON ILSE;DICIEMBRE;17/12/2023;10;10;10;10;7 chimeneas ;Nada;Mejor de lo que esperaba;Nada, todo perfecto \n",
      "19;MADRID EN FEMENINO;AGOSTO;12/08/2023;8;8;9;9;Al restaurante Sobrinos de Botín;El mapa final, hacia muchísimo sol;Mejor de lo que esperaba;Combinar mas las explicaciones de las mujeres con las explicaciones sobre la historia y tmb explicar las la conexión de las mujeres con los lugares que se visitan\n",
      "3;MADRID EN FEMENINO;SEPTIEMBRE;02/09/2023;9;10;10;10;Amabilidad y conocimiento de la guía turística;;Mejor de lo que esperaba;Más visitas y en distintos horarios\n",
      "19;LA LATINA Y EL MUSEO DE LOS ORIGENES;SEPTIEMBRE;16/09/2023;10;10;10;10;Beatriz Galindo latina ;Nada;Mejor de lo que esperaba;Me han gustado mucho \n",
      "35;LA LATINA Y EL MUSEO DE LOS ORIGENES;OCTUBRE;22/10/2023;7;8;8;8;Bien ;Bien ;Mejor de lo que esperaba;Bien \n",
      "20;MADRID MONUMENTAL;JULIO;28/07/2023;10;9;9;9;Calle Alcalá ;Nada ;Como esperaba;\n",
      "15;LA HISTORIA IMPRESCINDIBLE DE MADRID;AGOSTO;11/08/2023;10;10;10;10;;;Como esperaba;Amplia nuevas visitas de historia de Madrid \n",
      "20;TRADICIONES NAVIDEÑAS;DICIEMBRE;30/12/2023;8;10;10;10;Descubrir  datos nuevos sobre las tradiciones;Nada;Mejor de lo que esperaba;Ninguna\n",
      "19;MUJERES QUE HAN HECHO HISTORIA EN MADRID;OCTUBRE;13/10/2023;10;10;10;10;Destacar la labor del guía Cristian, haciendo de la actividad algo muy interesante y ameno con sus explicaciones y su trato para con nosotros. ;Nada;Mejor de lo que esperaba;Nos encantaría repetir con XXX en alguna otra visita interesante sobre la historia de Madrid \n"
     ]
    }
   ],
   "source": [
    "!head ./datos/Turismo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCSV = spark.read.options(sep=\";\", header=True, inferSchema=True).csv(\"datos/Turismo.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- VISITA: string (nullable = true)\n",
      " |-- MES: string (nullable = true)\n",
      " |-- FECHA: string (nullable = true)\n",
      " |-- SATISFACCION_INFOR: integer (nullable = true)\n",
      " |-- SATISFACCION_RECORRIDO: integer (nullable = true)\n",
      " |-- SATISFACCION_GUIA: integer (nullable = true)\n",
      " |-- SATISFACCION_GLOBAL: integer (nullable = true)\n",
      " |-- LO_MEJOR: string (nullable = true)\n",
      " |-- LO_PEOR: string (nullable = true)\n",
      " |-- OPINION: string (nullable = true)\n",
      " |-- SUGERENCIAS: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+----------+------------------+----------------------+-----------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| ID|              VISITA|       MES|     FECHA|SATISFACCION_INFOR|SATISFACCION_RECORRIDO|SATISFACCION_GUIA|SATISFACCION_GLOBAL|            LO_MEJOR|             LO_PEOR|             OPINION|         SUGERENCIAS|\n",
      "+---+--------------------+----------+----------+------------------+----------------------+-----------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 12|LEYENDAS, CASAS E...| DICIEMBRE|17/12/2023|                10|                    10|               10|                 10|        7 chimeneas |                Nada|Mejor de lo que e...|Nada, todo perfecto |\n",
      "| 19|  MADRID EN FEMENINO|    AGOSTO|12/08/2023|                 8|                     8|                9|                  9|Al restaurante So...|El mapa final, ha...|Mejor de lo que e...|Combinar mas las ...|\n",
      "|  3|  MADRID EN FEMENINO|SEPTIEMBRE|02/09/2023|                 9|                    10|               10|                 10|Amabilidad y cono...|                NULL|Mejor de lo que e...|Más visitas y en ...|\n",
      "| 19|LA LATINA Y EL MU...|SEPTIEMBRE|16/09/2023|                10|                    10|               10|                 10|Beatriz Galindo l...|                Nada|Mejor de lo que e...|Me han gustado mu...|\n",
      "| 35|LA LATINA Y EL MU...|   OCTUBRE|22/10/2023|                 7|                     8|                8|                  8|               Bien |               Bien |Mejor de lo que e...|               Bien |\n",
      "+---+--------------------+----------+----------+------------------+----------------------+-----------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCSV = dfCSV.withColumn(\"Fecha\", to_date(dfCSV.FECHA, \"dd/MM/yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- VISITA: string (nullable = true)\n",
      " |-- MES: string (nullable = true)\n",
      " |-- Fecha: date (nullable = true)\n",
      " |-- SATISFACCION_INFOR: integer (nullable = true)\n",
      " |-- SATISFACCION_RECORRIDO: integer (nullable = true)\n",
      " |-- SATISFACCION_GUIA: integer (nullable = true)\n",
      " |-- SATISFACCION_GLOBAL: integer (nullable = true)\n",
      " |-- LO_MEJOR: string (nullable = true)\n",
      " |-- LO_PEOR: string (nullable = true)\n",
      " |-- OPINION: string (nullable = true)\n",
      " |-- SUGERENCIAS: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+-----+------------------+----------------------+-----------------+-------------------+--------------------+-------+--------------------+--------------------+\n",
      "| ID|              VISITA|      MES|Fecha|SATISFACCION_INFOR|SATISFACCION_RECORRIDO|SATISFACCION_GUIA|SATISFACCION_GLOBAL|            LO_MEJOR|LO_PEOR|             OPINION|         SUGERENCIAS|\n",
      "+---+--------------------+---------+-----+------------------+----------------------+-----------------+-------------------+--------------------+-------+--------------------+--------------------+\n",
      "| 15|LA HISTORIA IMPRE...|   AGOSTO| NULL|                10|                    10|               10|                 10|                NULL|   NULL|       Como esperaba|Amplia nuevas vis...|\n",
      "|  3|    MADRID HISTÓRICO|    MARZO| NULL|                10|                    10|               10|                 10|El conjunto está ...|   NULL|Mejor de lo que e...|                NULL|\n",
      "| 20|TRADICIONES NAVID...|DICIEMBRE| NULL|                 8|                    10|               10|                 10|Descubrir  datos ...|   Nada|Mejor de lo que e...|             Ninguna|\n",
      "+---+--------------------+---------+-----+------------------+----------------------+-----------------+-------------------+--------------------+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.sort(dfCSV.SATISFACCION_GLOBAL.desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 MES|count|\n",
      "+--------------------+-----+\n",
      "|             OCTUBRE|   41|\n",
      "|          SEPTIEMBRE|   36|\n",
      "|               ABRIL|   34|\n",
      "|           DICIEMBRE|   32|\n",
      "|              AGOSTO|   31|\n",
      "|           NOVIEMBRE|   29|\n",
      "|               JULIO|   26|\n",
      "|               JUNIO|   21|\n",
      "|             FEBRERO|   18|\n",
      "|                Mayo|   14|\n",
      "|              ENERO |   13|\n",
      "|                NULL|    6|\n",
      "|               MARZO|    3|\n",
      "|Creo que podrían ...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.groupBy(\"MES\").count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un pequeño error en alguna columna y hay unos nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|              VISITA|SATISFACCION_GLOBAL|\n",
      "+--------------------+-------------------+\n",
      "|  MADRID EN FEMENINO|                 10|\n",
      "|LA LATINA Y EL MU...|                 10|\n",
      "|  MADRID EN FEMENINO|                  9|\n",
      "|   MADRID MONUMENTAL|                 10|\n",
      "|   MADRID MONUMENTAL|                 10|\n",
      "|  MADRID EN FEMENINO|                  6|\n",
      "|  MADRID EN FEMENINO|                  6|\n",
      "|LA HISTORIA IMPRE...|                 10|\n",
      "|LA LATINA Y EL MU...|                  9|\n",
      "|  MADRID EN FEMENINO|                  8|\n",
      "|LA HISTORIA IMPRE...|                 10|\n",
      "|   MADRID MONUMENTAL|                 10|\n",
      "|  MADRID EN FEMENINO|                  8|\n",
      "|HISTORIAS Y LEYEN...|                  9|\n",
      "|HISTORIAS Y LEYEN...|                 10|\n",
      "|LA NUEVA PLAZA DE...|                 10|\n",
      "|LA NUEVA PLAZA DE...|                 10|\n",
      "|LA NUEVA PLAZA DE...|                 10|\n",
      "|LA NUEVA PLAZA DE...|                 10|\n",
      "|LA LATINA Y EL MU...|                 10|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.select(\"VISITA\",\"SATISFACCION_GLOBAL\").filter(dfCSV.MES == \"SEPTIEMBRE\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCSV=dfCSV.na.fill(\"Sin comentarios\", subset=[\"LO_PEOR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-----+------------------+----------------------+-----------------+-------------------+--------+-------+-------+-----------+\n",
      "| ID|VISITA|MES|Fecha|SATISFACCION_INFOR|SATISFACCION_RECORRIDO|SATISFACCION_GUIA|SATISFACCION_GLOBAL|LO_MEJOR|LO_PEOR|OPINION|SUGERENCIAS|\n",
      "+---+------+---+-----+------------------+----------------------+-----------------+-------------------+--------+-------+-------+-----------+\n",
      "+---+------+---+-----+------------------+----------------------+-----------------+-------------------+--------+-------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCSV.filter(dfCSV.LO_PEOR.isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartado 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por motivos desconocidos esto crea una subcarpeta llamada Turismo.csv en la carpeta datos \n",
    "#dfCSV.write.mode(\"overwrite\").csv(\"datos/Turismo.csv\")\n",
    "\n",
    "# Eto funciona\n",
    "dfCSV.toPandas().to_csv('datos/Turismo.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrolla una aplicación en PySpark Streaming que cuente la frecuencia de palabras en tiempo real.\n",
    "La entrada de datos se proporcionará manualmente a través de un servidor de socket. Y la salida de datos se mostrará por consola.\n",
    "\n",
    "    1. Mostrar la cuenta de las palabras utilizando ventanas fijas de 2 minutos de duración. \n",
    "\n",
    "Muestra los resultados sin que se trunquen para que se vea la información completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 19:53:51 WARN Utils: Your hostname, iadb-10 resolves to a loopback address: 127.0.1.1; using 172.20.104.46 instead (on interface wlp44s0f0)\n",
      "25/03/10 19:53:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/10 19:53:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n",
      "25/03/10 19:53:52 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n",
      "25/03/10 19:53:53 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-36034d02-4abd-417a-87bb-7c5be70e85c8. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "25/03/10 19:53:53 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|       o|    1|\n",
      "|   menos|    1|\n",
      "|     mas|    1|\n",
      "|funciona|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=64>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/socket.py\", line 707, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/context.py\", line 381, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/context.py\", line 2446, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "    ^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o14.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/iabd/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o29.awaitTermination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     36\u001b[0m wordCounts \u001b[38;5;241m=\u001b[39m words\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m     38\u001b[0m query \u001b[38;5;241m=\u001b[39m wordCounts \\\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 45\u001b[0m \u001b[43mssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/streaming/context.py:239\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03mWait for the execution to stop.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    time to wait in seconds\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jssc\u001b[38;5;241m.\u001b[39mawaitTerminationOrTimeout(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/IABD3_12/lib/python3.12/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o29.awaitTermination"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 19:54:03 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "\n",
    "import time\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\").appName(\"pyspark_dataframe\").getOrCreate()\n",
    ")\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9999) \\\n",
    "    .load()\n",
    "\n",
    "# Split the lines into words\n",
    "words = lines.select(\n",
    "   explode(\n",
    "       split(lines.value, \" \")\n",
    "   ).alias(\"word\")\n",
    ")\n",
    "\n",
    "# Generate running word count\n",
    "wordCounts = words.groupBy(\"word\").count()\n",
    "\n",
    "query = wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IABD3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
